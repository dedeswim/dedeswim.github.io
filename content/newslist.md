**[07/2025 - Meta Internship]** In July, I will start an internship in the GenAI Red Team at Meta.

**[04/2025 - SafeBench Prize]** [AgentDojo](https://agentdojo.spylab.ai) got a [SafeBench](https://www.mlsafety.org/safebench) First prize, worth USD 50'000.

**[04/2025 - CaMeL is out!]** The paper resulting from my intership at Google is finally [out](https://arxiv.org/abs/2503.18813). We propose a new method, to solve prompt injections *by design*.

**[10/2024 - Internship]** On October 1st I started as Student Researcher in the AI Red Team at Google. I will be working with Tianqi Fan and [Ilia Shumailov](https://www.cl.cam.ac.uk/~is410/) (Google DeepMind) on AI agents security.

**[09/2024 - Spotlight]** The [report](https://arxiv.org/abs/2406.07954) of our SaTML LLMs CTF has been accepted as **spotlight** at the NeurIPS D&B Track 2024! Also [AgentDojo](https://agentdojo.spylab.ai) and [JailbreakBench](https://jailbreakbench.github.io) were accepted.

**[04/2024 - Award]** *[Evading Black-box Classifiers Without Breaking Eggs](https://arxiv.org/abs/2306.02895)*, selected as Distinguished Paper Award Runner-up at IEEE SaTML 2024!

**[04/2024 - New Paper: *JailbreakBench: An Open Robustness Benchmark for Jailbreaking Large Language Models*]** We have a new paper about benchmarking LLM jailbreak attacks and defenses with a focus on transparency and reproducibility. Take a look [here](https://arxiv.org/abs/2404.01318).

**[12/2023 - SaTML 2024 news]** Presenting *[Evading Black-box Classifiers Without Breaking Eggs](https://arxiv.org/abs/2306.02895)*, and co-organizing the [LLMs CTF](https://ctf.spylab.ai).

**[06/2023 - New paper: *Privacy Side Channels in Machine Learning Systems*]**  We have a new paper, about side-channels in ML *systems*, i.e., by exploiting components other than the model. Spoiler alert: some of those components, on paper, are meant to **improve** privacy! Take a look [here](https://arxiv.org/abs/2309.05610).

**[06/2023 - New paper: *Evading Black-box Classifiers Without Breaking Eggs*]**  We uploaded on arXiv a new paper, where we propose a new real-world oriented metric for black-box decision-based attacks on security-critical systems. Take a look [here](https://arxiv.org/abs/2306.02895)!

**[11/2022 - *A Light Recipe to Train Robust Vision Transformers* accepted at SaTML]** The paper derived from my master thesis was accepted at the [IEEE Conference on Secure and Trustworthy Machine Learning](https://satml.org) (SaTML 2023).

**[09/2022 - New paper: *A Light Recipe to Train Robust Vision Transformers*]**  We uploaded on arXiv the paper derived from my Master's thesis, with additional experiments and insights. Take a look [here](https://arxiv.org/abs/2209.07399).

**[08/2022 - I started my PhD]** On August 1st, 2022, I started my PhD at ETH Zürich, in the Privacy and Security Lab of Prof. [Florian Tramèr](https://floriantramer.com).

**[12/05/2022 - I earned my MSc at EPFL!]** On April 27th I successfully defended my MSc thesis about Adversarially Robust Vision Transformers! You can read it [here](/publication/thesis/). Feel free to contact me if you have any questions about it!
