[{"authors":["edoardo"],"categories":null,"content":"I am a Computer Science Ph.D. Student at ETH Zürich, advised by Florian Tramèr. My interest is in how the current (and future) research about the security and privacy of machine learning systems can be applied to real-world systems. My aim is to understand what the threat models look like in the real-world, and, based on that, understand which attacks are feasible, and what defenses are most effective.\nI earned a Computer Science M.Sc. at EPFL, with a strong focus on Machine Learning and Security, and a Computer Engineering B.Sc. at PoliTo. I did my Master thesis about the robustness of Vision Transformers supervised by Princeton University’s Prof. Mittal, and I am one of the co-authors and maintainers of RobustBench, a standardized benchmark for adversarial robustness.\nI had internship experiences at Bloomberg LP, as an SWE intern, and at armasuisse CYD Campus, as a Research Intern, supervised by Prof. Humbert.\nI attended Military Navy College “F. Morosini”, in Venice, I am a member of LeadTheFuture, the leading mentoring program for STEM students in Italy, and I have been junior entrepreneur at JEToP.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"f28e12ec1377084c6f96ac549f2be14b","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am a Computer Science Ph.D. Student at ETH Zürich, advised by Florian Tramèr. My interest is in how the current (and future) research about the security and privacy of machine learning systems can be applied to real-world systems.","tags":null,"title":"Edoardo Debenedetti","type":"authors"},{"authors":["Edoardo Debenedetti","Nicholas Carlini","Florian Tramèr"],"categories":[],"content":"","date":1686065596,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1686065596,"objectID":"bf3f4dc9b217df79ec7212471987edae","permalink":"https://edoardo.science/publication/breaking_eggs/","publishdate":"2023-06-06T15:33:16Z","relpermalink":"/publication/breaking_eggs/","section":"publication","summary":"We propose a new real-world oriented metric for black-box decision-based attacks on security-critical systems","tags":[],"title":"Evading Black-box Classifiers Without Breaking Eggs","type":"publication"},{"authors":["Edoardo Debenedetti","Vikash Sehwag","Prateek Mittal"],"categories":[],"content":"","date":1663687996,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1663687996,"objectID":"fbb2b56df6505044500f810a7c069bff","permalink":"https://edoardo.science/publication/light_recipe/","publishdate":"2022-09-20T15:33:16Z","relpermalink":"/publication/light_recipe/","section":"publication","summary":"This paper shows that ViTs are highly suitable for adversarial training to achieve competitive performance and recommends that the community should avoid translating the canonical training recipes in ViTs to robust training and rethink common training choices in the context of adversarial training.","tags":[],"title":"A Light Recipe to Train Robust Vision Transformers","type":"publication"},{"authors":["Edoardo Debenedetti"],"categories":[],"content":"","date":1652358837,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1652358837,"objectID":"0f40cf545adf79432be77d9037b7794b","permalink":"https://edoardo.science/publication/thesis/","publishdate":"2022-05-12T12:33:57Z","relpermalink":"/publication/thesis/","section":"publication","summary":"My Master's thesis done at EPFL under the supervision of Princeton's Vikash Sehwag and Prof. Prateek Mittal, and EPFL's Prof. Troncoso. We show that we can obtain state of the art results in adversarial training using Vision Transformers (in particular with XCiT) on ImageNet.","tags":[],"title":"Adversarially Robust Vision Transformers","type":"publication"},{"authors":["Francesco Croce","Maksym Andriushchenko","Vikash Sehwag","Edoardo Debenedetti","Nicolas Flammarion","Mung Chiang","Prateek Mittal","Matthias Hein"],"categories":[],"content":"","date":1617007444,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1617007444,"objectID":"2c2bf09e35bb19092bef162197364a73","permalink":"https://edoardo.science/publication/robustbench/","publishdate":"2021-03-29T10:44:04+02:00","relpermalink":"/publication/robustbench/","section":"publication","summary":"As a research community, we are still lacking a systematic understanding of the progress on adversarial robustness which often makes it hard to identify the most promising ideas in training robust models. A key challenge in benchmarking robustness is that its evaluation is often error-prone leading to robustness overestimation. Our goal is to establish a standardized benchmark of adversarial robustness, which as accurately as possible reflects the robustness of the considered models within a reasonable computational budget. To this end, we start by considering the image classification task and introduce restrictions (possibly loosened in the future) on the allowed models and evaluate adversarial robustness with AutoAttack, an ensemble of white- and black-box attacks, which was recently shown in a large-scale study to improve almost all robustness evaluations compared to the original publications. To prevent overadaptation of new defenses to AutoAttack, we welcome external evaluations based on adaptive attacks, especially where AutoAttack flags a potential overestimation of robustness. Our leaderboard, hosted at https://robustbench.github.io/, contains evaluations of 120+ models and aims at reflecting the current state of the art in image classification on a set of well-defined tasks in $\\ell_2$- and $\\ell_\\infty$-threat models and on common corruptions, with possible extensions in the future. Additionally, we open-source the library https://github.com/RobustBench/robustbench that provides unified access to 80+ robust models to facilitate their downstream applications. Finally, based on the collected models, we analyze the impact of robustness on the performance on distribution shifts, calibration, out-of-distribution detection, fairness, privacy leakage, smoothness, and transferability. ","tags":[],"title":"RobustBench: A standardized benchmark for adversarial robustness","type":"publication"},{"authors":null,"categories":null,"content":"\r[06/2023 - New paper: Evading Black-box Classifiers Without Breaking Eggs] We uploaded on arXiv a new paper, where we propose a new real-world oriented metric for black-box decision-based attacks on security-critical systems. Take a look here!\n[11/2022 - A Light Recipe to Train Robust Vision Transformers accepted at SaTML] The paper derived from my master thesis was accepted at the IEEE Conference on Secure and Trustworthy Machine Learning (SaTML). I’m looking forward to presenting my paper in February!\n[09/2022 - New paper: A Light Recipe to Train Robust Vision Transformers] We uploaded on arXiv the paper derived from my Master’s thesis, with additional experiments and insights. Take a look here!\n[08/2022 - I started my PhD] On August 1st, 2022, I started my PhD at ETH Zürich, in the Privacy and Security Lab of Prof. Florian Tramèr.\n[12/05/2022 - I earned my MSc at EPFL!] On April 27th I successfully defended my MSc thesis about Adversarially Robust Vision Transformers! You can read it here. Feel free to contact me if you have any questions about it!\n","date":1512086400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1512086400,"objectID":"a0812ae5f3c926fea6faf4472cefc8e2","permalink":"https://edoardo.science/news/","publishdate":"2017-12-01T00:00:00Z","relpermalink":"/news/","section":"","summary":"List of news.\r\n","tags":[],"title":"News","type":"page"},{"authors":null,"categories":null,"content":"[06/2023 - New paper: Evading Black-box Classifiers Without Breaking Eggs] We uploaded on arXiv a new paper, where we propose a new real-world oriented metric for black-box decision-based attacks on security-critical systems. Take a look here!\n[11/2022 - A Light Recipe to Train Robust Vision Transformers accepted at SaTML] The paper derived from my master thesis was accepted at the IEEE Conference on Secure and Trustworthy Machine Learning (SaTML). I’m looking forward to presenting my paper in February!\n[09/2022 - New paper: A Light Recipe to Train Robust Vision Transformers] We uploaded on arXiv the paper derived from my Master’s thesis, with additional experiments and insights. Take a look here!\n[08/2022 - I started my PhD] On August 1st, 2022, I started my PhD at ETH Zürich, in the Privacy and Security Lab of Prof. Florian Tramèr.\n[12/05/2022 - I earned my MSc at EPFL!] On April 27th I successfully defended my MSc thesis about Adversarially Robust Vision Transformers! You can read it here. Feel free to contact me if you have any questions about it!\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"4ba0b231c7eeb0b6fffbbe093c76caa6","permalink":"https://edoardo.science/newslist/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/newslist/","section":"","summary":"[06/2023 - New paper: Evading Black-box Classifiers Without Breaking Eggs] We uploaded on arXiv a new paper, where we propose a new real-world oriented metric for black-box decision-based attacks on security-critical systems.","tags":null,"title":"","type":"page"}]