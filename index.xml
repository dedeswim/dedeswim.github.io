<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Edoardo Debenedetti</title><link>https://edoardo.science/</link><atom:link href="https://edoardo.science/index.xml" rel="self" type="application/rss+xml"/><description>Edoardo Debenedetti</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sat, 06 Jan 2024 15:33:16 +0000</lastBuildDate><image><url>https://edoardo.science/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_512x512_fill_lanczos_center_3.png</url><title>Edoardo Debenedetti</title><link>https://edoardo.science/</link></image><item><title>Evading Black-box Classifiers Without Breaking Eggs</title><link>https://edoardo.science/publication/breaking_eggs/</link><pubDate>Sat, 06 Jan 2024 15:33:16 +0000</pubDate><guid>https://edoardo.science/publication/breaking_eggs/</guid><description/></item><item><title>Privacy Side Channels in Machine Learning Systems</title><link>https://edoardo.science/publication/side_channels/</link><pubDate>Tue, 12 Sep 2023 12:22:16 +0000</pubDate><guid>https://edoardo.science/publication/side_channels/</guid><description/></item><item><title>A Light Recipe to Train Robust Vision Transformers</title><link>https://edoardo.science/publication/light_recipe/</link><pubDate>Tue, 20 Sep 2022 15:33:16 +0000</pubDate><guid>https://edoardo.science/publication/light_recipe/</guid><description/></item><item><title>Adversarially Robust Vision Transformers</title><link>https://edoardo.science/publication/thesis/</link><pubDate>Thu, 12 May 2022 12:33:57 +0000</pubDate><guid>https://edoardo.science/publication/thesis/</guid><description/></item><item><title>RobustBench: A standardized benchmark for adversarial robustness</title><link>https://edoardo.science/publication/robustbench/</link><pubDate>Mon, 29 Mar 2021 10:44:04 +0200</pubDate><guid>https://edoardo.science/publication/robustbench/</guid><description/></item><item><title>News</title><link>https://edoardo.science/news/</link><pubDate>Fri, 01 Dec 2017 00:00:00 +0000</pubDate><guid>https://edoardo.science/news/</guid><description>
&lt;p>&lt;strong>[12/2023 - SaTML 2024 news]&lt;/strong> Presenting &lt;em>&lt;a href="https://arxiv.org/abs/2306.02895" target="_blank" rel="noopener">Evading Black-box Classifiers Without Breaking Eggs&lt;/a>&lt;/em>, and co-organizing the &lt;a href="https://ctf.spylab.ai" target="_blank" rel="noopener">LLMs CTF&lt;/a>!&lt;/p>
&lt;p>&lt;strong>[06/2023 - New paper: &lt;em>Privacy Side Channels in Machine Learning Systems&lt;/em>]&lt;/strong> We have a new paper, about side-channels in ML &lt;em>systems&lt;/em>, i.e., by exploiting components other than the model. Spoiler alert: some of those components, on paper, are meant to &lt;strong>improve&lt;/strong> privacy! Take a look &lt;a href="https://arxiv.org/abs/2309.05610" target="_blank" rel="noopener">here&lt;/a>!&lt;/p>
&lt;p>&lt;strong>[06/2023 - New paper: &lt;em>Evading Black-box Classifiers Without Breaking Eggs&lt;/em>]&lt;/strong> We uploaded on arXiv a new paper, where we propose a new real-world oriented metric for black-box decision-based attacks on security-critical systems. Take a look &lt;a href="https://arxiv.org/abs/2306.02895" target="_blank" rel="noopener">here&lt;/a>!&lt;/p>
&lt;p>&lt;strong>[11/2022 - &lt;em>A Light Recipe to Train Robust Vision Transformers&lt;/em> accepted at SaTML]&lt;/strong> The paper derived from my master thesis was accepted at the &lt;a href="https://satml.org" target="_blank" rel="noopener">IEEE Conference on Secure and Trustworthy Machine Learning&lt;/a> (SaTML).&lt;/p>
&lt;p>&lt;strong>[09/2022 - New paper: &lt;em>A Light Recipe to Train Robust Vision Transformers&lt;/em>]&lt;/strong> We uploaded on arXiv the paper derived from my Master&amp;rsquo;s thesis, with additional experiments and insights. Take a look &lt;a href="https://arxiv.org/abs/2209.07399" target="_blank" rel="noopener">here&lt;/a>!&lt;/p>
&lt;p>&lt;strong>[08/2022 - I started my PhD]&lt;/strong> On August 1st, 2022, I started my PhD at ETH Zürich, in the Privacy and Security Lab of Prof. &lt;a href="https://floriantramer.com" target="_blank" rel="noopener">Florian Tramèr&lt;/a>.&lt;/p>
&lt;p>&lt;strong>[12/05/2022 - I earned my MSc at EPFL!]&lt;/strong> On April 27th I successfully defended my MSc thesis about Adversarially Robust Vision Transformers! You can read it &lt;a href="https://edoardo.science/publication/thesis/">here&lt;/a>. Feel free to contact me if you have any questions about it!&lt;/p></description></item><item><title/><link>https://edoardo.science/newslist/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://edoardo.science/newslist/</guid><description>&lt;p>&lt;strong>[12/2023 - SaTML 2024 news]&lt;/strong> Presenting &lt;em>&lt;a href="https://arxiv.org/abs/2306.02895" target="_blank" rel="noopener">Evading Black-box Classifiers Without Breaking Eggs&lt;/a>&lt;/em>, and co-organizing the &lt;a href="https://ctf.spylab.ai" target="_blank" rel="noopener">LLMs CTF&lt;/a>!&lt;/p>
&lt;p>&lt;strong>[06/2023 - New paper: &lt;em>Privacy Side Channels in Machine Learning Systems&lt;/em>]&lt;/strong> We have a new paper, about side-channels in ML &lt;em>systems&lt;/em>, i.e., by exploiting components other than the model. Spoiler alert: some of those components, on paper, are meant to &lt;strong>improve&lt;/strong> privacy! Take a look &lt;a href="https://arxiv.org/abs/2309.05610" target="_blank" rel="noopener">here&lt;/a>!&lt;/p>
&lt;p>&lt;strong>[06/2023 - New paper: &lt;em>Evading Black-box Classifiers Without Breaking Eggs&lt;/em>]&lt;/strong> We uploaded on arXiv a new paper, where we propose a new real-world oriented metric for black-box decision-based attacks on security-critical systems. Take a look &lt;a href="https://arxiv.org/abs/2306.02895" target="_blank" rel="noopener">here&lt;/a>!&lt;/p>
&lt;p>&lt;strong>[11/2022 - &lt;em>A Light Recipe to Train Robust Vision Transformers&lt;/em> accepted at SaTML]&lt;/strong> The paper derived from my master thesis was accepted at the &lt;a href="https://satml.org" target="_blank" rel="noopener">IEEE Conference on Secure and Trustworthy Machine Learning&lt;/a> (SaTML).&lt;/p>
&lt;p>&lt;strong>[09/2022 - New paper: &lt;em>A Light Recipe to Train Robust Vision Transformers&lt;/em>]&lt;/strong> We uploaded on arXiv the paper derived from my Master&amp;rsquo;s thesis, with additional experiments and insights. Take a look &lt;a href="https://arxiv.org/abs/2209.07399" target="_blank" rel="noopener">here&lt;/a>!&lt;/p>
&lt;p>&lt;strong>[08/2022 - I started my PhD]&lt;/strong> On August 1st, 2022, I started my PhD at ETH Zürich, in the Privacy and Security Lab of Prof. &lt;a href="https://floriantramer.com" target="_blank" rel="noopener">Florian Tramèr&lt;/a>.&lt;/p>
&lt;p>&lt;strong>[12/05/2022 - I earned my MSc at EPFL!]&lt;/strong> On April 27th I successfully defended my MSc thesis about Adversarially Robust Vision Transformers! You can read it &lt;a href="https://edoardo.science/publication/thesis/">here&lt;/a>. Feel free to contact me if you have any questions about it!&lt;/p></description></item></channel></rss>