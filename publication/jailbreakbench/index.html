<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 5.7.0 for Hugo"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Fira+Sans&family=Fira+Code&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Fira+Sans&family=Fira+Code&display=swap" media=print onload='this.media="all"'><script src=/js/mathjax-config.js></script>
<link rel=stylesheet href=/css/vendor-bundle.min.047268c6dd09ad74ba54a0ba71837064.css media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/academicons@1.9.2/css/academicons.min.css integrity="sha512-KlJCpRsLf+KKu2VQa5vmRuClRFjxc5lXO03ixZt82HZUk41+1I0bD8KBSA0fY290ayMfWYI9udIqeOWSu1/uZg==" crossorigin=anonymous media=print onload='this.media="all"'><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js integrity crossorigin=anonymous async></script>
<link rel=stylesheet href=/css/wowchemy.bba687d229709d201099e637a1c464c1.css><link rel=stylesheet href=/css/libs/chroma/github-light.min.css title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=/css/libs/chroma/dracula.min.css title=hl-dark media=print onload='this.media="all"' disabled><meta name=author content="Edoardo Debenedetti"><meta name=description content="Jailbreak attacks cause large language models (LLMs) to generate harmful, unethical, or otherwise objectionable content. Evaluating these attacks presents a number of challenges, which the current collection of benchmarks and evaluation techniques do not adequately address. First, there is no clear standard of practice regarding jailbreaking evaluation. Second, existing works compute costs and success rates in incomparable ways. And third, numerous works are not reproducible, as they withhold adversarial prompts, involve closed-source code, or rely on evolving proprietary APIs. To address these challenges, we introduce JailbreakBench, an open-sourced benchmark with the following components: (1) an evolving repository of state-of-the-art adversarial prompts, which we refer to as jailbreak artifacts; (2) a jailbreaking dataset comprising 100 behaviors -- both original and sourced from prior work (Zou et al., 2023; Mazeika et al., 2023, 2024) -- which align with OpenAI's usage policies; (3) a standardized evaluation framework at [this https URL](https://github.com/JailbreakBench/jailbreakbench) that includes a clearly defined threat model, system prompts, chat templates, and scoring functions; and (4) a leaderboard at [this https URL](https://jailbreakbench.github.io/) that tracks the performance of attacks and defenses for various LLMs. We have carefully considered the potential ethical implications of releasing this benchmark, and believe that it will be a net positive for the community."><link rel=alternate hreflang=en-us href=https://edoardo.science/publication/jailbreakbench/><link rel=canonical href=https://edoardo.science/publication/jailbreakbench/><link rel=manifest href=/manifest.webmanifest><meta name=theme-color content="#1565c0"><meta property="twitter:card" content="summary"><meta property="twitter:site" content="@edoardo_debe"><meta property="twitter:creator" content="@edoardo_debe"><meta property="twitter:image" content="https://edoardo.science/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_512x512_fill_lanczos_center_3.png"><meta property="og:site_name" content="Edoardo Debenedetti"><meta property="og:url" content="https://edoardo.science/publication/jailbreakbench/"><meta property="og:title" content="JailbreakBench: An Open Robustness Benchmark for Jailbreaking Large Language Models | Edoardo Debenedetti"><meta property="og:description" content="Jailbreak attacks cause large language models (LLMs) to generate harmful, unethical, or otherwise objectionable content. Evaluating these attacks presents a number of challenges, which the current collection of benchmarks and evaluation techniques do not adequately address. First, there is no clear standard of practice regarding jailbreaking evaluation. Second, existing works compute costs and success rates in incomparable ways. And third, numerous works are not reproducible, as they withhold adversarial prompts, involve closed-source code, or rely on evolving proprietary APIs. To address these challenges, we introduce JailbreakBench, an open-sourced benchmark with the following components: (1) an evolving repository of state-of-the-art adversarial prompts, which we refer to as jailbreak artifacts; (2) a jailbreaking dataset comprising 100 behaviors -- both original and sourced from prior work (Zou et al., 2023; Mazeika et al., 2023, 2024) -- which align with OpenAI's usage policies; (3) a standardized evaluation framework at [this https URL](https://github.com/JailbreakBench/jailbreakbench) that includes a clearly defined threat model, system prompts, chat templates, and scoring functions; and (4) a leaderboard at [this https URL](https://jailbreakbench.github.io/) that tracks the performance of attacks and defenses for various LLMs. We have carefully considered the potential ethical implications of releasing this benchmark, and believe that it will be a net positive for the community."><meta property="og:image" content="https://edoardo.science/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_512x512_fill_lanczos_center_3.png"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="2024-10-09T14:11:22+00:00"><meta property="article:modified_time" content="2024-12-09T14:11:22+00:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://edoardo.science/publication/jailbreakbench/"},"headline":"JailbreakBench: An Open Robustness Benchmark for Jailbreaking Large Language Models","datePublished":"2024-10-09T14:11:22Z","dateModified":"2024-12-09T14:11:22Z","author":{"@type":"Person","name":"Patrick Chao"},"publisher":{"@type":"Organization","name":"Edoardo Debenedetti","logo":{"@type":"ImageObject","url":"https://edoardo.science/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_192x192_fill_lanczos_center_3.png"}},"description":"Jailbreak attacks cause large language models (LLMs) to generate harmful, unethical, or otherwise objectionable content. Evaluating these attacks presents a number of challenges, which the current collection of benchmarks and evaluation techniques do not adequately address. First, there is no clear standard of practice regarding jailbreaking evaluation. Second, existing works compute costs and success rates in incomparable ways. And third, numerous works are not reproducible, as they withhold adversarial prompts, involve closed-source code, or rely on evolving proprietary APIs. To address these challenges, we introduce JailbreakBench, an open-sourced benchmark with the following components: (1) an evolving repository of state-of-the-art adversarial prompts, which we refer to as jailbreak artifacts; (2) a jailbreaking dataset comprising 100 behaviors -- both original and sourced from prior work (Zou et al., 2023; Mazeika et al., 2023, 2024) -- which align with OpenAI's usage policies; (3) a standardized evaluation framework at [this https URL](https://github.com/JailbreakBench/jailbreakbench) that includes a clearly defined threat model, system prompts, chat templates, and scoring functions; and (4) a leaderboard at [this https URL](https://jailbreakbench.github.io/) that tracks the performance of attacks and defenses for various LLMs. We have carefully considered the potential ethical implications of releasing this benchmark, and believe that it will be a net positive for the community."}</script><title>JailbreakBench: An Open Robustness Benchmark for Jailbreaking Large Language Models | Edoardo Debenedetti</title><script async defer src=https://scripts.simpleanalyticscdn.com/latest.js></script><noscript><img src=https://queue.simpleanalyticscdn.com/noscript.gif alt referrerpolicy=no-referrer-when-downgrade></noscript></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=5768e7444dbcb445516b78153b51ef0c><script src=/js/wowchemy-init.min.ec9d49ca50e4b80bdb08f0417a28ed84.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class="page-header header--fixed"><header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#><span>Home</span></a></li><li class=nav-item><a class="nav-link active" href=/publication><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/files/cv.pdf><span>CV</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span></a>
<a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span></a>
<a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></header></div><div class=page-body><div class=pub><div class="article-container pt-3"><h1>JailbreakBench: An Open Robustness Benchmark for Jailbreaking Large Language Models</h1><div class=article-metadata><div><span>Patrick Chao</span>, <span>Edoardo Debenedetti</span>, <span>Alexander Robey</span>, <span>Maksym Andriushchenko</span>, <span>Francesco Croce</span>, <span>Vikash Sehwag</span>, <span>Edgar Dobriban</span>, <span>Nicolas Flammarion</span>, <span>George J. Pappas</span>, <span>Florian Tram√®r</span>, <span>Hamed Hassani</span>, <span>Eric Wong</span></div><span class=article-date>December, 2024</span></div><div class="btn-links mb-3"><a class="btn btn-outline-primary btn-page-header" href=https://arxiv.org/abs/2404.01318 target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header js-cite-modal" data-filename=/publication/jailbreakbench/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header" href=https://github.com/JailbreakBench/jailbreakbench target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header" href=https://huggingface.co/datasets/JailbreakBench/JBB-Behaviors target=_blank rel=noopener>Dataset</a>
<a class="btn btn-outline-primary btn-page-header" href=https://jailbreakbench.github.io target=_blank rel=noopener>Project</a></div></div><div class=article-container><h3>Abstract</h3><p class=pub-abstract>Jailbreak attacks cause large language models (LLMs) to generate harmful, unethical, or otherwise objectionable content. Evaluating these attacks presents a number of challenges, which the current collection of benchmarks and evaluation techniques do not adequately address. First, there is no clear standard of practice regarding jailbreaking evaluation. Second, existing works compute costs and success rates in incomparable ways. And third, numerous works are not reproducible, as they withhold adversarial prompts, involve closed-source code, or rely on evolving proprietary APIs. To address these challenges, we introduce JailbreakBench, an open-sourced benchmark with the following components: (1) an evolving repository of state-of-the-art adversarial prompts, which we refer to as jailbreak artifacts; (2) a jailbreaking dataset comprising 100 behaviors &ndash; both original and sourced from prior work (Zou et al., 2023; Mazeika et al., 2023, 2024) &ndash; which align with OpenAI&rsquo;s usage policies; (3) a standardized evaluation framework at <a href=https://github.com/JailbreakBench/jailbreakbench target=_blank rel=noopener>this https URL</a> that includes a clearly defined threat model, system prompts, chat templates, and scoring functions; and (4) a leaderboard at <a href=https://jailbreakbench.github.io/ target=_blank rel=noopener>this https URL</a> that tracks the performance of attacks and defenses for various LLMs. We have carefully considered the potential ethical implications of releasing this benchmark, and believe that it will be a net positive for the community.</p><div class=row><div class=col-md-1></div><div class=col-md-10><div class=row><div class="col-12 col-md-3 pub-row-heading">Type</div><div class="col-12 col-md-9"><a href=/publication/#1>Conference paper</a></div></div></div><div class=col-md-1></div></div><div class="d-md-none space-below"></div><div class=row><div class=col-md-1></div><div class=col-md-10><div class=row><div class="col-12 col-md-3 pub-row-heading">Publication</div><div class="col-12 col-md-9">NeurIPS 2024 Datasets and Benchmarks Track</div></div></div><div class=col-md-1></div></div><div class="d-md-none space-below"></div><div class=space-below></div><div class=article-style></div><div class=share-box><ul class=share><li><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fedoardo.science%2Fpublication%2Fjailbreakbench%2F&text=JailbreakBench%3A+An+Open+Robustness+Benchmark+for+Jailbreaking+Large+Language+Models" target=_blank rel=noopener class=share-btn-twitter aria-label=twitter><i class="fab fa-twitter"></i></a></li><li><a href="https://www.facebook.com/sharer.php?u=https%3A%2F%2Fedoardo.science%2Fpublication%2Fjailbreakbench%2F&t=JailbreakBench%3A+An+Open+Robustness+Benchmark+for+Jailbreaking+Large+Language+Models" target=_blank rel=noopener class=share-btn-facebook aria-label=facebook><i class="fab fa-facebook"></i></a></li><li><a href="mailto:?subject=JailbreakBench%3A%20An%20Open%20Robustness%20Benchmark%20for%20Jailbreaking%20Large%20Language%20Models&body=https%3A%2F%2Fedoardo.science%2Fpublication%2Fjailbreakbench%2F" target=_blank rel=noopener class=share-btn-email aria-label=envelope><i class="fas fa-envelope"></i></a></li><li><a href="https://www.linkedin.com/shareArticle?url=https%3A%2F%2Fedoardo.science%2Fpublication%2Fjailbreakbench%2F&title=JailbreakBench%3A+An+Open+Robustness+Benchmark+for+Jailbreaking+Large+Language+Models" target=_blank rel=noopener class=share-btn-linkedin aria-label=linkedin-in><i class="fab fa-linkedin-in"></i></a></li><li><a href="https://web.whatsapp.com/send?text=JailbreakBench%3A+An+Open+Robustness+Benchmark+for+Jailbreaking+Large+Language+Models%20https%3A%2F%2Fedoardo.science%2Fpublication%2Fjailbreakbench%2F" target=_blank rel=noopener class=share-btn-whatsapp aria-label=whatsapp><i class="fab fa-whatsapp"></i></a></li><li><a href="https://reddit.com/submit?url=https%3A%2F%2Fedoardo.science%2Fpublication%2Fjailbreakbench%2F&title=JailbreakBench%3A+An+Open+Robustness+Benchmark+for+Jailbreaking+Large+Language+Models" target=_blank rel=noopener class=share-btn-reddit aria-label=reddit-alien><i class="fab fa-reddit-alien"></i></a></li></ul></div></div></div></div><div class=page-footer><div class=container><footer class=site-footer><p class=powered-by>Powered by the
<a href=https://wowchemy.com/ target=_blank rel=noopener>Wowchemy theme</a> for
<a href=https://gohugo.io target=_blank rel=noopener>Hugo</a>, kindly hosted by <a href=https://github.io target=_blank rel=noopener>GitHub Pages</a>, deployed with GitHub Actions.
<span class=float-right aria-hidden=true><a href=# class=back-to-top><span class=button_icon><i class="fas fa-chevron-up fa-2x"></i></span></a></span></p></footer></div></div><script src=/js/vendor-bundle.min.1d4346c6f7d46c340dc0a9058dd85c13.js></script>
<script id=search-hit-fuse-template type=text/x-template>
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script><script src=https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin=anonymous></script>
<script id=page-data type=application/json>{"use_headroom":true}</script><script src=/js/wowchemy-headroom.db4755770454eb63685f8de785c0a172.js type=module></script>
<script src=/en/js/wowchemy.min.c84202fca2a6efbbecbaf0e8358c1d51.js></script><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=/js/wowchemy-publication.68f8d7090562ca65fc6d3cb3f8f2d2cb.js type=module></script></body></html>