<!doctype html><html lang=en-us>
<head>
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1">
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=generator content="Wowchemy 5.0.0-beta.3 for Hugo">
<meta name=author content="Edoardo Debenedetti">
<meta name=description content="As a research community, we are still lacking a systematic understanding of the progress on adversarial robustness which often makes it hard to identify the most promising ideas in training robust models. A key challenge in benchmarking robustness is that its evaluation is often error-prone leading to robustness overestimation. Our goal is to establish a standardized benchmark of adversarial robustness, which as accurately as possible reflects the robustness of the considered models within a reasonable computational budget. To this end, we start by considering the image classification task and introduce restrictions (possibly loosened in the future) on the allowed models and evaluate adversarial robustness with AutoAttack, an ensemble of white- and black-box attacks, which was recently shown in a large-scale study to improve almost all robustness evaluations compared to the original publications. To prevent overadaptation of new defenses to AutoAttack, we welcome external evaluations based on adaptive attacks, especially where AutoAttack flags a potential overestimation of robustness. Our leaderboard, hosted at https://robustbench.github.io/, contains evaluations of 120+ models and aims at reflecting the current state of the art in image classification on a set of well-defined tasks in - and -threat models and on common corruptions, with possible extensions in the future. Additionally, we open-source the library https://github.com/RobustBench/robustbench that provides unified access to 80+ robust models to facilitate their downstream applications. Finally, based on the collected models, we analyze the impact of robustness on the performance on distribution shifts, calibration, out-of-distribution detection, fairness, privacy leakage, smoothness, and transferability. ">
<link rel=alternate hreflang=en-us href=https://edoardo.science/publication/robustbench/>
<link rel=preconnect href=https://fonts.gstatic.com crossorigin>
<meta name=theme-color content="#01579b">
<script src=/js/mathjax-config.js></script>
<link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin=anonymous>
<link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin=anonymous>
<script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js integrity crossorigin=anonymous async></script>
<link rel=stylesheet href="https://fonts.googleapis.com/css?family=Bebas+Neue%7CIBM+Plex+Mono&display=swap">
<link rel=stylesheet href=/css/wowchemy.f523c45d30f03c11025040263a2c1c44.css>
<link rel=manifest href=/index.webmanifest>
<link rel=icon type=image/png href=/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_32x32_fill_lanczos_center_3.png>
<link rel=apple-touch-icon type=image/png href=/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_180x180_fill_lanczos_center_3.png>
<link rel=canonical href=https://edoardo.science/publication/robustbench/>
<meta property="twitter:card" content="summary">
<meta property="twitter:site" content="@edoardo_debe">
<meta property="twitter:creator" content="@edoardo_debe">
<meta property="og:site_name" content="Edoardo Debenedetti">
<meta property="og:url" content="https://edoardo.science/publication/robustbench/">
<meta property="og:title" content="RobustBench: A standardized benchmark for adversarial robustness | Edoardo Debenedetti">
<meta property="og:description" content="As a research community, we are still lacking a systematic understanding of the progress on adversarial robustness which often makes it hard to identify the most promising ideas in training robust models. A key challenge in benchmarking robustness is that its evaluation is often error-prone leading to robustness overestimation. Our goal is to establish a standardized benchmark of adversarial robustness, which as accurately as possible reflects the robustness of the considered models within a reasonable computational budget. To this end, we start by considering the image classification task and introduce restrictions (possibly loosened in the future) on the allowed models and evaluate adversarial robustness with AutoAttack, an ensemble of white- and black-box attacks, which was recently shown in a large-scale study to improve almost all robustness evaluations compared to the original publications. To prevent overadaptation of new defenses to AutoAttack, we welcome external evaluations based on adaptive attacks, especially where AutoAttack flags a potential overestimation of robustness. Our leaderboard, hosted at https://robustbench.github.io/, contains evaluations of 120+ models and aims at reflecting the current state of the art in image classification on a set of well-defined tasks in - and -threat models and on common corruptions, with possible extensions in the future. Additionally, we open-source the library https://github.com/RobustBench/robustbench that provides unified access to 80+ robust models to facilitate their downstream applications. Finally, based on the collected models, we analyze the impact of robustness on the performance on distribution shifts, calibration, out-of-distribution detection, fairness, privacy leakage, smoothness, and transferability. "><meta property="og:image" content="https://edoardo.science/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_512x512_fill_lanczos_center_3.png">
<meta property="twitter:image" content="https://edoardo.science/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_512x512_fill_lanczos_center_3.png"><meta property="og:locale" content="en-us">
<meta property="article:published_time" content="2021-03-29T10:44:04+02:00">
<meta property="article:modified_time" content="2021-10-12T11:48:09+02:00">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://edoardo.science/publication/robustbench/"},"headline":"RobustBench: A standardized benchmark for adversarial robustness","datePublished":"2021-03-29T10:44:04+02:00","dateModified":"2021-10-12T11:48:09+02:00","author":{"@type":"Person","name":"Francesco Croce"},"publisher":{"@type":"Organization","name":"Edoardo Debenedetti","logo":{"@type":"ImageObject","url":"https://edoardo.science/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_192x192_fill_lanczos_center_3.png"}},"description":"As a research community, we are still lacking a systematic understanding of the progress on adversarial robustness which often makes it hard to identify the most promising ideas in training robust models. A key challenge in benchmarking robustness is that its evaluation is often error-prone leading to robustness overestimation. Our goal is to establish a standardized benchmark of adversarial robustness, which as accurately as possible reflects the robustness of the considered models within a reasonable computational budget. To this end, we start by considering the image classification task and introduce restrictions (possibly loosened in the future) on the allowed models and evaluate adversarial robustness with AutoAttack, an ensemble of white- and black-box attacks, which was recently shown in a large-scale study to improve almost all robustness evaluations compared to the original publications. To prevent overadaptation of new defenses to AutoAttack, we welcome external evaluations based on adaptive attacks, especially where AutoAttack flags a potential overestimation of robustness. Our leaderboard, hosted at https://robustbench.github.io/, contains evaluations of 120+ models and aims at reflecting the current state of the art in image classification on a set of well-defined tasks in - and -threat models and on common corruptions, with possible extensions in the future. Additionally, we open-source the library https://github.com/RobustBench/robustbench that provides unified access to 80+ robust models to facilitate their downstream applications. Finally, based on the collected models, we analyze the impact of robustness on the performance on distribution shifts, calibration, out-of-distribution detection, fairness, privacy leakage, smoothness, and transferability. "}</script>
<script async defer data-domain=edoardo.science src=https://plausible.io/js/plausible.js></script>
<title>RobustBench: A standardized benchmark for adversarial robustness | Edoardo Debenedetti</title>
</head>
<body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=2c2bf09e35bb19092bef162197364a73>
<script src=/js/wowchemy-init.min.eca9bbc7a71accd5ebd9eee0ff004132.js></script>
<div class=page-header>
<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main>
<div class=container-xl>
<button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span>
</button>
<div class="navbar-collapse main-menu-item collapse justify-content-end" id=navbar-content>
<ul class="navbar-nav d-md-inline-flex">
<li class=nav-item>
<a class=nav-link href=/#hero><span>Home</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/#projects><span>Projects</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/#posts><span>Posts</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/#contact><span>Contact me</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/cv.pdf><span>CV</span></a>
</li>
</ul>
</div>
<ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
<li class="nav-item dropdown theme-dropdown">
<a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences">
<i class="fas fa-moon" aria-hidden=true></i>
</a>
<div class=dropdown-menu>
<a href=# class="dropdown-item js-set-theme-light">
<span>Light</span>
</a>
<a href=# class="dropdown-item js-set-theme-dark">
<span>Dark</span>
</a>
<a href=# class="dropdown-item js-set-theme-auto">
<span>Automatic</span>
</a>
</div>
</li>
</ul>
</div>
</nav>
</div>
<div class=page-body>
<div class=pub>
<div class="article-container pt-3">
<h1>RobustBench: A standardized benchmark for adversarial robustness</h1>
<div class=article-metadata>
<div>
<span>
<a href=/author/francesco-croce/>Francesco Croce</a></span>, <span>
<a href=/author/maksym-andriushchenko/>Maksym Andriushchenko</a></span>, <span>
<a href=/author/vikash-sehwag/>Vikash Sehwag</a></span>, <span>
<a href=/author/edoardo-debenedetti/>Edoardo Debenedetti</a></span>, <span>
<a href=/author/nicolas-flammarion/>Nicolas Flammarion</a></span>, <span>
<a href=/author/mung-chiang/>Mung Chiang</a></span>, <span>
<a href=/author/prateek-mittal/>Prateek Mittal</a></span>, <span>
<a href=/author/matthias-hein/>Matthias Hein</a></span>
</div>
<span class=article-date>
March 2021
</span>
</div>
<div class="btn-links mb-3">
<a class="btn btn-outline-primary btn-page-header" href="https://openreview.net/forum?id=SSKZPJCt7B" target=_blank rel=noopener>
PDF
</a>
<a href=# class="btn btn-outline-primary btn-page-header js-cite-modal" data-filename=/publication/robustbench/cite.bib>
Cite
</a>
<a class="btn btn-outline-primary btn-page-header" href=https://github.com/RobustBench/robustbench target=_blank rel=noopener>
Code
</a>
</div>
</div>
<div class=article-container>
<h3>Abstract</h3>
<p class=pub-abstract>As a research community, we are still lacking a systematic understanding of the progress on adversarial robustness which often makes it hard to identify the most promising ideas in training robust models. A key challenge in benchmarking robustness is that its evaluation is often error-prone leading to robustness overestimation. Our goal is to establish a standardized benchmark of adversarial robustness, which as accurately as possible reflects the robustness of the considered models within a reasonable computational budget. To this end, we start by considering the image classification task and introduce restrictions (possibly loosened in the future) on the allowed models and evaluate adversarial robustness with AutoAttack, an ensemble of white- and black-box attacks, which was recently shown in a large-scale study to improve almost all robustness evaluations compared to the original publications. To prevent overadaptation of new defenses to AutoAttack, we welcome external evaluations based on adaptive attacks, especially where AutoAttack flags a potential overestimation of robustness. Our leaderboard, hosted at <a href=https://robustbench.github.io/,>https://robustbench.github.io/,</a> contains evaluations of 120+ models and aims at reflecting the current state of the art in image classification on a set of well-defined tasks in - and -threat models and on common corruptions, with possible extensions in the future. Additionally, we open-source the library <a href=https://github.com/RobustBench/robustbench>https://github.com/RobustBench/robustbench</a> that provides unified access to 80+ robust models to facilitate their downstream applications. Finally, based on the collected models, we analyze the impact of robustness on the performance on distribution shifts, calibration, out-of-distribution detection, fairness, privacy leakage, smoothness, and transferability.</p>
<div class=row>
<div class=col-md-1></div>
<div class=col-md-10>
<div class=row>
<div class="col-12 col-md-3 pub-row-heading">Type</div>
<div class="col-12 col-md-9">
<a href=/publication/#1>
Conference paper
</a>
</div>
</div>
</div>
<div class=col-md-1></div>
</div>
<div class="d-md-none space-below"></div>
<div class=row>
<div class=col-md-1></div>
<div class=col-md-10>
<div class=row>
<div class="col-12 col-md-3 pub-row-heading">Publication</div>
<div class="col-12 col-md-9">Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track</div>
</div>
</div>
<div class=col-md-1></div>
</div>
<div class="d-md-none space-below"></div>
<div class=space-below></div>
<div class=article-style></div>
<div class=share-box aria-hidden=true>
<ul class=share>
<li>
<a href="https://twitter.com/intent/tweet?url=https://edoardo.science/publication/robustbench/&text=RobustBench:%20A%20standardized%20benchmark%20for%20adversarial%20robustness" target=_blank rel=noopener class=share-btn-twitter>
<i class="fab fa-twitter"></i>
</a>
</li>
<li>
<a href="https://www.facebook.com/sharer.php?u=https://edoardo.science/publication/robustbench/&t=RobustBench:%20A%20standardized%20benchmark%20for%20adversarial%20robustness" target=_blank rel=noopener class=share-btn-facebook>
<i class="fab fa-facebook"></i>
</a>
</li>
<li>
<a href="mailto:?subject=RobustBench:%20A%20standardized%20benchmark%20for%20adversarial%20robustness&body=https://edoardo.science/publication/robustbench/" target=_blank rel=noopener class=share-btn-email>
<i class="fas fa-envelope"></i>
</a>
</li>
<li>
<a href="https://www.linkedin.com/shareArticle?url=https://edoardo.science/publication/robustbench/&title=RobustBench:%20A%20standardized%20benchmark%20for%20adversarial%20robustness" target=_blank rel=noopener class=share-btn-linkedin>
<i class="fab fa-linkedin-in"></i>
</a>
</li>
<li>
<a href="https://web.whatsapp.com/send?text=RobustBench:%20A%20standardized%20benchmark%20for%20adversarial%20robustness%20https://edoardo.science/publication/robustbench/" target=_blank rel=noopener class=share-btn-whatsapp>
<i class="fab fa-whatsapp"></i>
</a>
</li>
<li>
<a href="https://reddit.com/submit?url=https://edoardo.science/publication/robustbench/&title=RobustBench:%20A%20standardized%20benchmark%20for%20adversarial%20robustness" target=_blank rel=noopener class=share-btn-reddit>
<i class="fab fa-reddit-alien"></i>
</a>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class=page-footer>
<div class=container>
<footer class=site-footer>
<p class=powered-by>
</p>
<p class=powered-by>
© 2021 Edoardo Debenedetti. This work is licensed under a <a href=http://creativecommons.org/licenses/by-sa/4.0/>Creative Commons Attribution-ShareAlike 4.0 International License</a> &#183;
Powered by the
<a href=https://wowchemy.com/ target=_blank rel=noopener>Wowchemy theme</a> for
<a href=https://gohugo.io target=_blank rel=noopener>Hugo</a>, kindly hosted by <a href=https://github.io target=_blank rel=noopener>GitHub Pages</a>, deployed with GitHub Actions.
<span class=float-right aria-hidden=true>
<a href=# class=back-to-top>
<span class=button_icon>
<i class="fas fa-chevron-up fa-2x"></i>
</span>
</a>
</span>
</p>
</footer>
</div>
</div>
<div id=modal class="modal fade" role=dialog>
<div class=modal-dialog>
<div class=modal-content>
<div class=modal-header>
<h5 class=modal-title>Cite</h5>
<button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span>
</button>
</div>
<div class=modal-body>
<pre><code class="tex hljs"></code></pre>
</div>
<div class=modal-footer>
<a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank>
<i class="fas fa-copy"></i> Copy
</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank>
<i class="fas fa-download"></i> Download
</a>
<div id=modal-error></div>
</div>
</div>
</div>
</div>
<script src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin=anonymous></script>
<script src=/js/_vendor/bootstrap.bundle.min.f81d0a1705048649befc8b595e455a94.js></script>
<script src=/en/js/wowchemy.min.5882c5cb8e3931044690cf26faac0e30.js></script>
</body>
</html>